{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain.memory import ConversationSummaryMemory, ConversationBufferMemory, CombinedMemory, ChatMessageHistory\n",
    "from langchain.chains import ConversationChain\n",
    "from typing import Any, Dict, Optional, Tuple\n",
    "\n",
    "import requests\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR API KEY\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://openai.vocareum.com/v1\"\n",
    "\n",
    "# Code to get the movie plot from Wikipedia\n",
    "def get_movie_plot(movie_name):\n",
    "    headers = {\n",
    "        'User-Agent': 'MoviePlotFetcher/1.0'\n",
    "    }\n",
    "    \n",
    "    base_url = f\"https://en.wikipedia.org/w/api.php\"\n",
    "        \n",
    "    def is_movie_page(title):\n",
    "        params = {\n",
    "            \"action\": \"query\",\n",
    "            \"format\": \"json\",\n",
    "            \"titles\": title,\n",
    "            \"prop\": \"categories|revisions\",\n",
    "            \"rvprop\": \"content\",\n",
    "            \"cllimit\": \"max\"\n",
    "        }\n",
    "    \n",
    "        response = requests.get(base_url, headers=headers, params=params)\n",
    "        data = response.json()\n",
    "    \n",
    "        try:\n",
    "            page = list(data[\"query\"][\"pages\"].values())[0]\n",
    "            \n",
    "            # Check categories for Movie indication\n",
    "            categories = [cat[\"title\"] for cat in page.get(\"categories\", [])]\n",
    "            for category in categories:\n",
    "                if \"films\" in category.lower():\n",
    "                    return True\n",
    "                    \n",
    "            # Check for infobox movie in the page content\n",
    "            content = page[\"revisions\"][0][\"*\"]\n",
    "            if \"{{Infobox film\" in content:\n",
    "                return True\n",
    "                \n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "        return False\n",
    "    \n",
    "    def extract_plot_from_text(full_text):\n",
    "        try:\n",
    "            # Find the start of the Plot section\n",
    "            plot_start = full_text.index(\"== Plot ==\") + len(\"== Plot ==\")\n",
    "            \n",
    "            # Find the start of the next section\n",
    "            next_section_start = full_text.find(\"==\", plot_start)\n",
    "\n",
    "            # If no next section is found, use the end of the text\n",
    "            if next_section_start == -1:\n",
    "                next_section_start = len(full_text)\n",
    "\n",
    "            # Extract the plot text and strip leading/trailing whitespace\n",
    "            plot_text = full_text[plot_start:next_section_start].strip()\n",
    "\n",
    "            # Return the extracted plot\n",
    "            return plot_text\n",
    "\n",
    "        except ValueError:\n",
    "            # Return a message if the Plot section isn't found\n",
    "            return \"Plot section not found in the text.\"\n",
    "        \n",
    "    def extract_first_paragraph(full_text):\n",
    "        # Find the first double newline\n",
    "        end_of_first_paragraph = full_text.find(\"\\n\\n\")\n",
    "\n",
    "        # If found, slice the string to get the first paragraph\n",
    "        if end_of_first_paragraph != -1:\n",
    "            return full_text[:end_of_first_paragraph].strip()\n",
    "\n",
    "        # If not found, return the whole text as it might be just one paragraph\n",
    "        return full_text.strip()\n",
    "\n",
    "    \n",
    "    search_params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"list\": \"search\",\n",
    "        \"srsearch\": movie_name,\n",
    "        \"utf8\": 1,\n",
    "        \"srlimit\": 5  # Top 5 search results\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url, headers=headers, params=search_params)\n",
    "    data = response.json()\n",
    "    \n",
    "    # Go through top search results to find a movie page\n",
    "    for search_result in data[\"query\"][\"search\"]:\n",
    "        title = search_result[\"title\"]\n",
    "        if is_movie_page(title):\n",
    "            # Fetch plot for the movie page\n",
    "            plot_params = {\n",
    "                \"action\": \"query\",\n",
    "                \"format\": \"json\",\n",
    "                \"titles\": title,\n",
    "                \"prop\": \"extracts\",\n",
    "                \"explaintext\": True,\n",
    "            }\n",
    "            \n",
    "            plot_response = requests.get(base_url, headers=headers, params=plot_params)\n",
    "            plot_data = plot_response.json()\n",
    "            \n",
    "            try:\n",
    "                page = list(plot_data[\"query\"][\"pages\"].values())[0]\n",
    "                full_text = page.get(\"extract\", \"No text...\")\n",
    "                return f\"\"\"Overview:\\n{extract_first_paragraph(full_text)}\\nPlot:\\n{extract_plot_from_text(full_text)}\"\"\".strip()\n",
    "            except:\n",
    "                return \"Error fetching plot.\"\n",
    "\n",
    "    return \"Movie not found.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, initialize your LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: initialize your llm with max_tokens=2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's setup some personal q/a over your movie preferences. Feel free to pick whichever questions you think will allow \n",
    "LLL to predict the movies you'll like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update these questions as you think will be the most helpful for your AI recommender\n",
    "personal_questions = [  \"Which movie genre you like the most?\", \n",
    "                        \"What is your favorite color?\", \n",
    "                        \"What is your favorite movie?\", \n",
    "                        \"Pick one - dogs, cats or hamsters?\",\n",
    "                        \"What is your favorite food?\",\n",
    "                        \"What is your favorite drink?\" ]\n",
    "\n",
    "# personal_answers = [ ] \n",
    "\n",
    "# for question in personal_questions:\n",
    "#    answer = input(question)\n",
    "#    personal_answers.append(answer)\n",
    "    \n",
    "# list of your personal answers to the questions above\n",
    "personal_answers = ['thriller', 'blue', 'inception', 'dogs', 'fish tacos', 'strawberry milkshake']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a list of recent movies that your LLM might not know anything about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of recent movies that you'd like AI to consider when recommending a movie\n",
    "movies = [ \"Barbie\", \"Oppenheimer\", \"The Notebook\", \"Dumb Money\" ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's setup a chat history between you and AI where we provide your answers to the questions AI \"asked\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = ChatMessageHistory()\n",
    "history.add_user_message(f\"\"\"You are AI that will recommend user a movie based on their answers to personal questions. Ask user {len(personal_questions)} questions\"\"\")\n",
    "# TODO: add questions and answers to the history\n",
    "    \n",
    "history.add_ai_message(\"\"\"Now tell me a plot summary of a movie you're considering watching, and specify how you want me to respond to you with the movie rating\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to load movie plots from Wikipedia, pass them to LLM and see how it would the movie for us based on our personal q/a\n",
    "Holding all movie plots and their recommendations within conversation would eventually put us over max tokens limit, so let's create a ConversationSummaryMemory \n",
    "that would hold a summary of our conversation and AI recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create a memory that will have a summary of the recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a PromptTemplate that would hold continuously updating summary of our conversation, our personal Q/A, and a placeholder for movie plot for AI to rate.\n",
    "Think about how you can pass your questions and answers into the template - there are many different ways to do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECOMMENDER_TEMPLATE = \"\"\"The following is a friendly conversation between a human and an AI Movie Recommender. \n",
    "                        The AI is follows human instructions and provides movie ratings for a human based on the movie plot. \n",
    "\n",
    "Summary of Recommendations:\n",
    "{recommendation_summary}\n",
    "Personal Questions and Answers:\n",
    "{questions_and_answers}\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    input_variables=[\"recommendation_summary\", \"input\", \"questions_and_answers\"],\n",
    "    template=RECOMMENDER_TEMPLATE\n",
    ")\n",
    "# create a recommendation conversation chain that will let us ask AI for recommendations on all movies\n",
    "recommender = ConversationChain(llm=llm, verbose=True, memory=memory, prompt=PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go thru a list of our movies, fetch their plots and run our recommendation chain for one movie at a time so we don't overload the context window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_rating = 100\n",
    "for movie in movies:\n",
    "    print(\"Movie: \" + movie)\n",
    "    movie_plot = get_movie_plot(movie)\n",
    "    \n",
    "    plot_rating_instructions = f\"\"\"\n",
    "         =====================================\n",
    "        === START MOVIE PLOT SUMMARY FOR {movie} ===\n",
    "        {movie_plot}\n",
    "        === END MOVIE PLOT SUMMARY ===\n",
    "        =====================================\n",
    "        \n",
    "        RATING INSTRUCTIONS THAT MUST BE STRICTLY FOLLOWED:\n",
    "        AI will provide a highly personalized rating based only on the movie plot summary human provided \n",
    "        and human answers to questions included with the context. \n",
    "        AI should be very sensible to human personal preferences captured in the answers to personal questions, \n",
    "        and should not be influenced by anything else.\n",
    "        AI will also build a persona for human based on human answers to questions, and use this persona to rate the movie.\n",
    "        OUTPUT FORMAT:\n",
    "        First, include that persona you came up with in the explanation for the rating. Describe the persona in a few sentences.\n",
    "        Explain how human preferences captured in the answers to personal questions influenced creation of this persona.\n",
    "        In addition, consider other ratings for this human that you might have as they might give you more information about human's preferences.\n",
    "        Your goal is to provide a rating that is as close as possible to the rating human would give to this movie.\n",
    "        Remember that human has very limited time and wants to see something they will like, so your rating should be as accurate as possible.\n",
    "        Rating will range from 1 to {max_rating}, with {max_rating} meaning human will love it, and 1 meaning human will hate it. \n",
    "        You will include a logical explanation for your rating based on human persona you've build and human responses to questions.\n",
    "        YOUR REVIEW MUST END WITH TEXT: \"RATING FOR MOVIE {movie} is \" FOLLOWED BY THE RATING.\n",
    "        FOLLOW THE INSTRUCTIONS STRICTLY, OTHERWISE HUMAN WILL NOT BE ABLE TO UNDERSTAND YOUR REVIEW.\n",
    "    \"\"\"\n",
    "    # TODO: run the the recommendation chain to get a rating for the movie that will be summarized in the conversation summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've initialized our chain to run in a verbose mode, and we will see full text that gets sent to the LLM\n",
    "Note how the summary keeps updating after each movie is recommended.\n",
    "Finally, once AI has rated all the movies, let's ask for the final recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_recommendation = \"\"\"Now that AI has rated all the movies, AI will recommend human the one that human will like the most. \n",
    "                            AI will respond with movie recommendation, and short explanation for why human will like it over all other movies. \n",
    "                            AI will not include any ratings in your explanation, only the reasons why human will like it the most.\n",
    "                            However, the movie you will pick must be one of the movies you rated the highest.\n",
    "                            For example, if you rated one movie 65, and the other 60, you will recommend the movie with rating 65 because rating 65 \n",
    "                            is greate than rating of 60 .\"\"\"\n",
    "\n",
    "# run recommendation once more to get the final movie recommendation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
