{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can solve a simple math problem with gpt-3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add prereq code to set open API key\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR API KEY\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://openai.vocareum.com/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "temperature = 0.0\n",
    "llm = OpenAI(model_name=model_name, temperature=temperature, max_tokens = 500)\n",
    "\n",
    "# Note: example taken from\n",
    "# https://browse.arxiv.org/pdf/2303.12712.pdf\n",
    "\n",
    "instruction = \"\"\"\n",
    "Andy harvests all the tomatoes from 18 plants that have 7 tomatoes each. If he dries half the\n",
    "tomatoes and turns a third of the remainder into marinara sauce, how many tomatoes are left?\n",
    "\"\"\"\n",
    "print(\"Original Answer: \")\n",
    "print(llm(instruction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we run this, we see an incorrect answer:\n",
    "Original Answer: \n",
    "Andy harvests a total of 18 plants * 7 tomatoes/plant = <<18*7=126>>126 tomatoes.\n",
    "He dries half of the tomatoes, so he has 126 tomatoes / 2 = <<126/2=63>>63 tomatoes left.\n",
    "He turns a third of the remaining tomatoes into marinara sauce, so he has 63 tomatoes * 1/3 = <<63*1/3=21>>21 tomatoes left. Answer: \\boxed{21}.\n",
    "\n",
    "In reality, Andy will have 63 - 21 = 42 tomatoes left\n",
    "\n",
    "Let's see how we can fix this with Chain Of Thought Reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's setup a examples of how we want LLM to think about the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "question1 = \"\"\"\n",
    "Karen harvests all the pears from 20 trees that have 10 pears each. She  throws a third of them away as they are rotten,\n",
    "and turns a quarter of the remaining ones into jam. How many are left?\n",
    "\"\"\"\n",
    "answer1 = \"\"\"\n",
    "    First, let's calculate how many pears Gloria harvests: it's 20 * 10 = 200. \n",
    "    Then, let's calculate how many are rotten: 200 * 1/3 = 66.\n",
    "    Thus, we know how many are left after she throws a third of them away: 200 - 66 = 134.\n",
    "    1/4 of the remaining ones are turned into jam, or 134 * 1/4 = 33. Therefore, Karen is left with 134 - 33, or 101 pears\n",
    "\"\"\"\n",
    "question2 = \"\"\"\n",
    "Sergei harvests all the strawberries from 50 plants that have 8 stawberries each. He freezes a quarter of them,\n",
    "and turns half of the remaining ones into jam. How many are left?\n",
    "\"\"\"\n",
    "answer2 = \"\"\"\n",
    "    First, let's calculate how many strawberries Sergei harvests: it's 50 * 8 = 400. \n",
    "    Then, let's calculate how many are frozen: 400 * 1/4 = 100.\n",
    "    Thus, we know how many are left after he freezes 100 of them: 400 - 100 = 300.\n",
    "    half of the remaining ones are turned into jam, or 300 * 1/2 = 150. Therefore, Sergei is left with 300 - 150, or 150 pears\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's setup an prompt template for one question/answer pair, and put our examples into an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = PromptTemplate(input_variables=[\"question\", \"answer\"], template=\"{question}\\n{answer}\")\n",
    "# TODO: setup an array of question / answer examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's setup the FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: setup chain of thought prompt template based on few shot prompt template\n",
    "cot_prompt = FewShotPromptTemplate(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's use the same instruction as before and see if we get a different answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cot_text = cot_prompt.format(input=instruction)\n",
    "print(\"=== Chain of Thought Prompt ===\")\n",
    "print(cot_text)\n",
    "print(\"=== Chain of Thought Answer ===\")\n",
    "print(llm(cot_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
